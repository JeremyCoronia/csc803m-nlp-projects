{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this BINARY CLASSIFIER to be used is [bc-dataset.csv].\r\n",
    "There are 2 implementations here:\r\n",
    "1. Bag of words approach.\r\n",
    "2. **Word vectors (can be pre-trained word embeddings).**\r\n",
    "\r\n",
    "The dataset split is 60-40.\r\n",
    "Evaluation metrics to be used in this are:\r\n",
    "1. Precision.\r\n",
    "2. Recall.\r\n",
    "3. F-Measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "(20050, 3)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ftfy import fix_encoding\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import csv\r\n",
    "import string \r\n",
    "import nltk as nlp\r\n",
    "from nltk.corpus import stopwords\r\n",
    "\r\n",
    "nlp.download(\"stopwords\")\r\n",
    "nlp.download('punkt')\r\n",
    "nlp.download('wordnet')\r\n",
    "\r\n",
    "def remove_URL(text):\r\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\r\n",
    "    return url.sub(r'',text)\r\n",
    "\r\n",
    "def remove_html(text):\r\n",
    "    html=re.compile(r'<.*?>')\r\n",
    "    return html.sub(r'',text)\r\n",
    "\r\n",
    "def remove_emoji(text):\r\n",
    "    emoji_pattern = re.compile(\"[\"\r\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\r\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\r\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\r\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\r\n",
    "                           u\"\\U00002702-\\U000027B0\"\r\n",
    "                           u\"\\U000024C2-\\U0001F251\"\r\n",
    "                           \"]+\", flags=re.UNICODE)\r\n",
    "    return emoji_pattern.sub(r'', text)\r\n",
    "\r\n",
    "def remove_punct(text):\r\n",
    "    table=str.maketrans('','',string.punctuation)\r\n",
    "    return text.translate(table)\r\n",
    "\r\n",
    "def fix_encode(x):\r\n",
    "    return fix_encoding(x)\r\n",
    "\r\n",
    "pd.set_option('display.max_rows', None)\r\n",
    "pd.set_option('display.max_colwidth', None)\r\n",
    "\r\n",
    "df = pd.read_csv(\r\n",
    "    \"datasets/bc-dataset.csv\",\r\n",
    "    encoding=\"latin1\",\r\n",
    "    sep=\",\",\r\n",
    "    quoting=csv.QUOTE_ALL\r\n",
    ")\r\n",
    "\r\n",
    "data = pd.concat([df.gender, df['gender:confidence'], df.description], axis=1)\r\n",
    "\r\n",
    "#drop null rows\r\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section does the following:\r\n",
    "1. Drops any rows containing NaN values in either the *description* or *gender* column.\r\n",
    "2. Drops any rows containing the string 'brand' in *gender*.\r\n",
    "3. Drops any rows containing values < **0.80** in the *gender:confidence* columm.\r\n",
    "4. Resets the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(8847, 2)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=['description', 'gender'], inplace=True)\r\n",
    "data = data.reset_index(drop=True)\r\n",
    "\r\n",
    "data.drop(data[data['gender'] == 'brand'].index, inplace=True)\r\n",
    "data = data.reset_index(drop=True)\r\n",
    "\r\n",
    "data.drop(data[data['gender:confidence'] < 0.80].index, inplace=True)\r\n",
    "data.drop('gender:confidence', axis=1, inplace=True)\r\n",
    "data = data.reset_index(drop=True)\r\n",
    "\r\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the rows for *male* and *female* genders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section does the following to the text:\r\n",
    "1. Fixes any broken encoding (via *ftfy*) that might have occurred when loading the file.\r\n",
    "2. Removes the URL.\r\n",
    "3. Removes HTML tags.\r\n",
    "4. Removes emojis.\r\n",
    "5. Removes punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(8847, 2)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.description = data.description.apply(lambda x: fix_encode(x))\r\n",
    "\r\n",
    "data['description']=data['description'].apply(lambda x : remove_URL(x))\r\n",
    "data['description']=data['description'].apply(lambda x : remove_html(x))\r\n",
    "data['description']=data['description'].apply(lambda x : remove_emoji(x))\r\n",
    "data['description']=data['description'].apply(lambda x : remove_punct(x))\r\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:  Owner of Itty Bitty the Pitty Scholar Writer Activist Unapologetic Fat Lady \n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL: \", data.description.iloc[5211])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section does the following to the text to finish off data preprocessing on the *description* column:\r\n",
    "1. Cleans unnecessary characters.\r\n",
    "2. Converts all string to lowercase.\r\n",
    "3. Splits by tokenizing.\r\n",
    "4. Deletes stopwords from the array.\r\n",
    "5. Lemmatizes the words. \r\n",
    "6. Joins them.\r\n",
    "7. Appends them to ```description_list``` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(8847, 2)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = nlp.WordNetLemmatizer()\r\n",
    "description_list = []\r\n",
    "\r\n",
    "for each in data.description:\r\n",
    "    each = re.sub(\"[^a-zA-Z]\",\" \", str(each))                                        \r\n",
    "    each = each.lower()                                                              \r\n",
    "    each = nlp.word_tokenize(each)                                                   \r\n",
    "    each = [word for word in each if not word in set(stopwords.words(\"english\"))]    \r\n",
    "    each = [lemma.lemmatize(word) for word in each]                                  \r\n",
    "    each = \" \".join(each)                                                           \r\n",
    "    # each = correct_spellings(each)                                                   # correct the spelling (?)\r\n",
    "    description_list.append(each)                                                    \r\n",
    "\r\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8847"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:  We are all Stardust\n",
      "PREPROCESSED:  stardust\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL: \", data.description.iloc[5232])\r\n",
    "print(\"PREPROCESSED: \", description_list[5232])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts all instances of female into value 0, and 1 for male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1    4227\n0    4620\nName: gender, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender = [0 if gender == 'female' else 1 for gender in data.gender]\r\n",
    "\r\n",
    "data['gender'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses ```CountVectorizer()``` to implement Bag-of-Words. The ``MAX_FEATURES`` variable determines the maximum number of features to be used during implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "MAX_FEATURES = 5000\r\n",
    "\r\n",
    "count_vectorizer = CountVectorizer(max_features=MAX_FEATURES, stop_words='english')\r\n",
    "sparse_matrix = count_vectorizer.fit_transform(description_list).toarray()\r\n",
    "words = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adult', 'advance', 'adventure', 'adventurer', 'adventurous', 'advertising', 'advice', 'adviser', 'advisor', 'advocacy', 'advocate', 'ae', 'aesthetic', 'af', 'afc', 'affair', 'affiliate', 'affiliated', 'aficionado', 'afraid', 'africa', 'african', 'afternoon', 'ag', 'age', 'agency', 'agent', 'agile', 'agree', 'agreement', 'aha', 'ahead', 'ahs', 'aim', 'aint', 'air', 'airplane', 'aka', 'al', 'alabama', 'album', 'ale', 'alex', 'alfie', 'alias', 'alien', 'alive', 'allah', 'allaround', 'alliance']\n"
     ]
    }
   ],
   "source": [
    "print(words[50:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train-test split is 60-40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X = sparse_matrix\r\n",
    "y = data.gender.values\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.ensemble import VotingClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier()"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 100)\r\n",
    "\r\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.6385984741452387"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy\r\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y pred\r\n",
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 63.67994680026639\n",
      "Precision: 63.85209610805469\n",
      "Recall: 63.85984741452388\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rfc)\r\n",
    "\r\n",
    "f_measure = f1_score(y_test, y_pred_rfc, average=\"weighted\")\r\n",
    "precision_measure = precision_score(y_test, y_pred_rfc, average=\"weighted\")\r\n",
    "recall_measure = recall_score(y_test, y_pred_rfc, average=\"weighted\")\r\n",
    "\r\n",
    "print(\"F1 Score:\", f_measure*100)\r\n",
    "print(\"Precision:\", precision_measure*100)\r\n",
    "print(\"Recall:\", recall_measure*100)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for confusion matrix\r\n",
    "sns.heatmap(cm, cbar=False, annot=True, cmap=\"Blues\", fmt=\"d\")\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.6645945182254874\n",
      "F-measure:  0.6617629833781742\n",
      "Precision:  0.666067246384434\n",
      "Recall:  0.6645945182254874\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\r\n",
    "# from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "\r\n",
    "\r\n",
    "nb = MultinomialNB()\r\n",
    "nb.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_nb = nb.predict(X_test)\r\n",
    "\r\n",
    "f_measure_nb = f1_score(y_test, y_pred_nb, average=\"weighted\")\r\n",
    "precision_measure_nb = precision_score(y_test, y_pred_nb, average=\"weighted\")\r\n",
    "recall_measure_nb = recall_score(y_test, y_pred_nb, average=\"weighted\")\r\n",
    "\r\n",
    "print(\"Mean accuracy: \", nb.score(X_test, y_test))\r\n",
    "print(\"F-measure: \", f_measure_nb)\r\n",
    "print(\"Precision: \", precision_measure_nb)\r\n",
    "print(\"Recall: \", recall_measure_nb)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.65635   0.74783   0.69911      1844\n",
      "           1    0.67663   0.57404   0.62113      1695\n",
      "\n",
      "    accuracy                        0.66459      3539\n",
      "   macro avg    0.66649   0.66094   0.66012      3539\n",
      "weighted avg    0.66607   0.66459   0.66176      3539\n",
      "\n",
      "Mean accuracy:  0.61514552133371\n",
      "WEIGHTED F-measure:  0.6617629833781742\n",
      "WEIGHTED Precision:  0.6267671457522654\n",
      "WEIGHTED Recall:  0.61514552133371\n"
     ]
    }
   ],
   "source": [
    "gnb_classifier = GaussianNB()\r\n",
    "gnb_classifier.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_gnb = gnb_classifier.predict(X_test)\r\n",
    "\r\n",
    "print(classification_report(y_test, y_pred_nb, digits=5))\r\n",
    "print(\"Mean accuracy: \", gnb_classifier.score(X_test, y_test))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test, y_pred_nb, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test, y_pred_gnb, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test, y_pred_gnb, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.6555524159367053\n",
      "F-measure:  0.6506759775295113\n",
      "Precision:  0.6589370303636944\n",
      "Recall:  0.6555524159367053\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\r\n",
    "lr = LogisticRegression(max_iter=2000)\r\n",
    "lr.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_lr = lr.predict(X_test)\r\n",
    "\r\n",
    "f_measure_lr = f1_score(y_test, y_pred_lr, average=\"weighted\")\r\n",
    "precision_measure_lr = precision_score(y_test, y_pred_lr, average=\"weighted\")\r\n",
    "recall_measure_lr = recall_score(y_test, y_pred_lr, average=\"weighted\")\r\n",
    "\r\n",
    "print(\"Mean accuracy: \", lr.score(X_test, y_test))\r\n",
    "print(\"F-measure: \", f_measure_lr)\r\n",
    "print(\"Precision: \", precision_measure_lr)\r\n",
    "print(\"Recall: \", recall_measure_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.5210511443910709\n",
      "F-measure:  0.35698246712135784\n",
      "Precision:  0.2714942950712446\n",
      "Recall:  0.5210511443910709\n"
     ]
    }
   ],
   "source": [
    "SVM = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto')\r\n",
    "SVM.fit(X_train,y_train)\r\n",
    "\r\n",
    "y_pred_svm = SVM.predict(X_test)\r\n",
    "\r\n",
    "f_measure_svm = f1_score(y_test, y_pred_svm, average=\"weighted\")\r\n",
    "precision_measure_svm = precision_score(y_test, y_pred_svm, average=\"weighted\")\r\n",
    "recall_measure_svm = recall_score(y_test, y_pred_svm, average=\"weighted\")\r\n",
    "\r\n",
    "print(\"Mean accuracy: \", SVM.score(X_test, y_test))\r\n",
    "print(\"F-measure: \", f_measure_svm)\r\n",
    "print(\"Precision: \", precision_measure_svm)\r\n",
    "print(\"Recall: \", recall_measure_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0f5bd28ee32a81f75b587c4a5c9ba5abfdf032b3105de37173de2ab9e920c5085"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}