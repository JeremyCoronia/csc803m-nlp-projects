{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this BINARY CLASSIFIER to be used is [bc-dataset.csv].\r\n",
    "There are 2 implementations here:\r\n",
    "1. **Bag of words approach.**\r\n",
    "2. Word vectors (can be pre-trained word embeddings).\r\n",
    "\r\n",
    "The dataset split is 60-40.\r\n",
    "Evaluation metrics to be used in this are:\r\n",
    "1. Precision.\r\n",
    "2. Recall.\r\n",
    "3. F-Measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (20050, 3)\n"
     ]
    }
   ],
   "source": [
    "from ftfy import fix_encoding\r\n",
    "import pandas as pd\r\n",
    "import random\r\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\r\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
    "from sklearn.utils import shuffle\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import csv\r\n",
    "import nltk as nlp\r\n",
    "from nltk.corpus import stopwords\r\n",
    "\r\n",
    "nlp.download(\"stopwords\")\r\n",
    "nlp.download('punkt')\r\n",
    "nlp.download('wordnet')\r\n",
    "\r\n",
    "def fix_encode(x):\r\n",
    "    return fix_encoding(x)\r\n",
    "\r\n",
    "pd.set_option('display.max_rows', None)\r\n",
    "pd.set_option('display.max_colwidth', None)\r\n",
    "\r\n",
    "df = pd.read_csv(\r\n",
    "    \"datasets/bc-dataset.csv\",\r\n",
    "    encoding=\"latin1\",\r\n",
    "    sep=\",\",\r\n",
    "    quoting=csv.QUOTE_ALL\r\n",
    ")\r\n",
    "\r\n",
    "data = pd.concat([df.gender, df['gender:confidence'], df.text], axis=1)\r\n",
    "\r\n",
    "#drop null rows\r\n",
    "print(\"Data Shape: \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows some descriptive stats (just for fun).\r\n",
    "Also applies ftfy encoding to the ['text'] Column to fix any broken encodings when the .csv file was loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (20050, 3)\n",
      "Data Columns: Index(['gender', 'gender:confidence', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape: \" + str(data.shape))\r\n",
    "print(\"Data Columns: \" + str(data.columns))\r\n",
    "\r\n",
    "# print(\"Just some stats.\")\r\n",
    "# print(\"------\")\r\n",
    "# print(data['gender'].describe())\r\n",
    "# print(\"------\")\r\n",
    "# print(data['gender'].value_counts(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNKNOWN and NAN values in *gender* column are discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total female tweets:  6700\n",
      "total male tweets:    6194\n",
      "total brand tweets:   5942\n"
     ]
    }
   ],
   "source": [
    "get_female = data[\"gender\"] == \"female\"\r\n",
    "get_male = data[\"gender\"] == \"male\"\r\n",
    "get_brand = data[\"gender\"] == \"brand\"\r\n",
    "\r\n",
    "female_rows = data[get_female]\r\n",
    "male_rows = data[get_male]\r\n",
    "brand_rows = data[get_brand]\r\n",
    "\r\n",
    "print(\"total female tweets: \", female_rows.text.count())\r\n",
    "print(\"total male tweets:   \", male_rows.text.count())\r\n",
    "print(\"total brand tweets:  \", brand_rows.text.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "female_rows.gender = 0     # female\r\n",
    "male_rows.gender = 1       # male\r\n",
    "brand_rows.gender = 2      # brand) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [female_rows, male_rows, brand_rows]\r\n",
    "data = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['gender', 'gender:confidence', 'text'], dtype='object')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing purposes\r\n",
    "# data.iloc[231]\r\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18836, 3)\n",
      "(18836, 3)\n"
     ]
    }
   ],
   "source": [
    "data.text = data.text.apply(lambda x: fix_encode(x))\r\n",
    "\r\n",
    "print(str(data.shape))\r\n",
    "data.dropna(subset=['text', 'gender'], inplace=True)\r\n",
    "data = data.reset_index(drop=True)\r\n",
    "\r\n",
    "# Data Shape: (20050, 26)\r\n",
    "# Data Shape: (16306, 26)\r\n",
    "print(str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \r\n",
    "\r\n",
    "def remove_URL(text):\r\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\r\n",
    "    return url.sub(r'',text)\r\n",
    "\r\n",
    "def remove_html(text):\r\n",
    "    html=re.compile(r'<.*?>')\r\n",
    "    return html.sub(r'',text)\r\n",
    "\r\n",
    "def remove_emoji(text):\r\n",
    "    emoji_pattern = re.compile(\"[\"\r\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\r\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\r\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\r\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\r\n",
    "                           u\"\\U00002702-\\U000027B0\"\r\n",
    "                           u\"\\U000024C2-\\U0001F251\"\r\n",
    "                           \"]+\", flags=re.UNICODE)\r\n",
    "    return emoji_pattern.sub(r'', text)\r\n",
    "\r\n",
    "def remove_punct(text):\r\n",
    "    table=str.maketrans('','',string.punctuation)\r\n",
    "    return text.translate(table)\r\n",
    "\r\n",
    "data['text']=data['text'].apply(lambda x : remove_URL(x))\r\n",
    "data['text']=data['text'].apply(lambda x : remove_html(x))\r\n",
    "data['text']=data['text'].apply(lambda x : remove_emoji(x))\r\n",
    "data['text']=data['text'].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:  illamiina yes exactly as I wouldve done when elena was drowning I dont see the difference\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL: \", data.text.iloc[8721])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13817, 2)\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[data['gender:confidence'] < 0.80].index, inplace=True)\r\n",
    "data.drop('gender:confidence', axis=1, inplace=True)\r\n",
    "# data.dropna(subset=['gender'], inplace=True)\r\n",
    "print(str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:  Girl of the month  \n",
      "PREPROCESSED:  girl month\n"
     ]
    }
   ],
   "source": [
    "lemma = nlp.WordNetLemmatizer()\r\n",
    "description_list = []   # empty list\r\n",
    "tweet_list = []   # empty list\r\n",
    "\r\n",
    "# should pronouns be counted as stopwords?\r\n",
    "\r\n",
    "for each in data.text:\r\n",
    "    each = re.sub(\"[^a-zA-Z]\",\" \", str(each))                                        # regex to clean unnecesarry chars\r\n",
    "    each = each.lower()                                                              # lowercase all\r\n",
    "    each = nlp.word_tokenize(each)                                                   # split all by tokenizing\r\n",
    "    each = [word for word in each if not word in set(stopwords.words(\"english\"))]    # delete stop words from your array\r\n",
    "    each = [lemma.lemmatize(word) for word in each]                                  # lemmatize \"memories\" -> \"memory\"\r\n",
    "    each = \" \".join(each)                                                            # make them one string again\r\n",
    "    tweet_list.append(each)                                                         # put them into big array\r\n",
    "\r\n",
    "print(\"ORIGINAL: \", data.text.iloc[123])\r\n",
    "print(\"PREPROCESSED: \", tweet_list[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13817, 2)\n"
     ]
    }
   ],
   "source": [
    "print(str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "# arbitrarily set it \r\n",
    "MAX_FEATURES = 4000\r\n",
    "count_vectorizer = CountVectorizer(max_features=MAX_FEATURES, stop_words='english')\r\n",
    "sparse_matrix = count_vectorizer.fit_transform(tweet_list).toarray()\r\n",
    "words = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(words[:100])\r\n",
    "\r\n",
    "X = sparse_matrix\r\n",
    "y = data.gender.values\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53722   0.64486   0.58614      2171\n",
      "           1    0.46228   0.40594   0.43228      1887\n",
      "           2    0.62342   0.53642   0.57666      1469\n",
      "\n",
      "    accuracy                        0.53447      5527\n",
      "   macro avg    0.54097   0.52907   0.53169      5527\n",
      "weighted avg    0.53455   0.53447   0.53109      5527\n",
      "\n",
      "Mean accuracy:  0.5344671612086123\n",
      "WEIGHTED F-measure:  0.5310898368047072\n",
      "WEIGHTED Precision:  0.5345456549441825\n",
      "WEIGHTED Recall:  0.5344671612086123\n"
     ]
    }
   ],
   "source": [
    "# metrics\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "nb_classifier = MultinomialNB()\r\n",
    "nb_classifier.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_nb = nb_classifier.predict(X_test)\r\n",
    "\r\n",
    "print(classification_report(y_test, y_pred_nb, digits=5))\r\n",
    "print(\"Mean accuracy: \", nb_classifier.score(X_test, y_test))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test, y_pred_nb, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test, y_pred_nb, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test, y_pred_nb, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.52846   0.59880   0.56143      2171\n",
      "           1    0.44501   0.41600   0.43002      1887\n",
      "           2    0.59094   0.52417   0.55556      1469\n",
      "\n",
      "    accuracy                        0.51656      5527\n",
      "   macro avg    0.52147   0.51299   0.51567      5527\n",
      "weighted avg    0.51657   0.51656   0.51500      5527\n",
      "\n",
      "Mean accuracy:  0.5165550931789398\n",
      "WEIGHTED F-measure:  0.5150045420458254\n",
      "WEIGHTED Precision:  0.5165749081319531\n",
      "WEIGHTED Recall:  0.5165550931789398\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(max_iter=5000)\r\n",
    "lr_classifier.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_lr = lr_classifier.predict(X_test)\r\n",
    "\r\n",
    "print(classification_report(y_test, y_pred_lr, digits=5))\r\n",
    "print(\"Mean accuracy: \", lr_classifier.score(X_test, y_test))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test, y_pred_lr, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test, y_pred_lr, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test, y_pred_lr, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.51171   0.59374   0.54968      2171\n",
      "           1    0.42167   0.39799   0.40949      1887\n",
      "           2    0.61043   0.50987   0.55564      1469\n",
      "\n",
      "    accuracy                        0.50461      5527\n",
      "   macro avg    0.51461   0.50053   0.50494      5527\n",
      "weighted avg    0.50721   0.50461   0.50340      5527\n",
      "\n",
      "Mean accuracy:  0.5046137144924914\n",
      "WEIGHTED F-measure:  0.5033997976294795\n",
      "WEIGHTED Precision:  0.5072094202377095\n",
      "WEIGHTED Recall:  0.5046137144924914\n"
     ]
    }
   ],
   "source": [
    "rfc_classifier = RandomForestClassifier(n_estimators = 100)\r\n",
    "rfc_classifier.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_head_rfc = rfc_classifier.predict(X_test)\r\n",
    "\r\n",
    "print(classification_report(y_test, y_head_rfc, digits=5))\r\n",
    "print(\"Mean accuracy: \", rfc_classifier.score(X_test, y_test))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test, y_head_rfc, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test, y_head_rfc, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test, y_head_rfc, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier()"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.5678853277500403"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy\r\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y pred\r\n",
    "y_head_ml = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "cm = confusion_matrix(y_test, y_head_ml)\r\n",
    "\r\n",
    "f_measure = f1_score(y_test, y_head_ml, average=\"weighted\")\r\n",
    "precision_measure = precision_score(y_test, y_head_ml, average=\"weighted\")\r\n",
    "recall_measure = recall_score(y_test, y_head_ml, average=\"weighted\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5650056724691268\n",
      "0.5687736486936054\n",
      "0.5678853277500403\n"
     ]
    }
   ],
   "source": [
    "print(f_measure)\r\n",
    "print(precision_measure)\r\n",
    "print(recall_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for confusion matrix\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "sns.heatmap(cm, cbar=False, annot=True, cmap=\"Blues\", fmt=\"d\")\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.5864068287969078\n",
      "F-measure:  0.5829820294973996\n",
      "Precision:  0.5928806822075628\n",
      "Recall:  0.5864068287969078\n"
     ]
    }
   ],
   "source": [
    "# for quick and dirty counting\r\n",
    "from collections import defaultdict\r\n",
    "\r\n",
    "# the Naive Bayes model\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "# function to split the data for cross-validation\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "# function for transforming documents into counts\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "# function for encoding categories\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "\r\n",
    "nb = MultinomialNB()\r\n",
    "nb.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_nb = nb.predict(X_test)\r\n",
    "\r\n",
    "f_measure_nb = f1_score(y_test, y_pred_nb, average=\"weighted\")\r\n",
    "precision_measure_nb = precision_score(y_test, y_pred_nb, average=\"weighted\")\r\n",
    "recall_measure_nb = recall_score(y_test, y_pred_nb, average=\"weighted\")\r\n",
    "\r\n",
    "print(\"Mean accuracy: \", nb.score(X_test, y_test))\r\n",
    "print(\"F-measure: \", f_measure_nb)\r\n",
    "print(\"Precision: \", precision_measure_nb)\r\n",
    "print(\"Recall: \", recall_measure_nb)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.5864068287969078\n",
      "F-measure:  0.5704928489224667\n",
      "Precision:  0.5819557132712734\n",
      "Recall:  0.5725559671444677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "# Logistic Regression\r\n",
    "lr = LogisticRegression(max_iter=2000)\r\n",
    "lr.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_lr = lr.predict(X_test)\r\n",
    "\r\n",
    "f_measure_lr = f1_score(y_test, y_pred_lr, average=\"weighted\")\r\n",
    "precision_measure_lr = precision_score(y_test, y_pred_lr, average=\"weighted\")\r\n",
    "recall_measure_lr = recall_score(y_test, y_pred_lr, average=\"weighted\")\r\n",
    "\r\n",
    "print(\"Mean accuracy: \", nb.score(X_test, y_test))\r\n",
    "print(\"F-measure: \", f_measure_lr)\r\n",
    "print(\"Precision: \", precision_measure_lr)\r\n",
    "print(\"Recall: \", recall_measure_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0f5bd28ee32a81f75b587c4a5c9ba5abfdf032b3105de37173de2ab9e920c5085"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}