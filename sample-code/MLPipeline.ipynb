{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads in the 2 files. I dropped the columns I felt would not be used throughout the pipeline. Users are also filtered based on if they have a Twitter account and if their Nationality mentions Filipino anywhere. The *3rd* file is the tweets with the auto-generated tweets removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftfy import fix_encoding\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import csv\r\n",
    "# from tweetokenize import Tokenizer\r\n",
    "\r\n",
    "traits = [\r\n",
    "\t\"Openness\", \r\n",
    "\t\"Extraversion\",\r\n",
    "\t\"Conscientiousness\",\r\n",
    "\t\"Agreeableness\",\r\n",
    "\t\"Neuroticism\"]\r\n",
    "\r\n",
    "def fix_encode(x):\r\n",
    "    return fix_encoding(x)\r\n",
    "\r\n",
    "pd.set_option('display.max_rows', None)\r\n",
    "pd.set_option('display.max_colwidth', None)\r\n",
    "\r\n",
    "df_twt_tweets = pd.read_csv(\r\n",
    "    \"twitter_tweet.csv\",\r\n",
    "    encoding=\"utf-8\",\r\n",
    "    sep=\",\",\r\n",
    "    quoting=csv.QUOTE_ALL)\r\n",
    "\r\n",
    "# df_twt_tweets.to_csv(\r\n",
    "#     r'C:/Users/LENOVO/Desktop/MS/CSC802M/lab-datasets/final/twitter_tweet.csv',\r\n",
    "#     quoting=csv.QUOTE_ALL)\r\n",
    "\r\n",
    "df_filtered_users = pd.read_csv(\r\n",
    "    \"filtered_users.csv\",\r\n",
    "    encoding=\"utf-8\",\r\n",
    "    sep=\",\",\r\n",
    "    quoting=csv.QUOTE_ALL)\r\n",
    "\r\n",
    "df_processed_tweets = pd.read_csv(\r\n",
    "    \"processed_tweets_dataset_nonconcat.csv\",\r\n",
    "    encoding=\"utf-8\",\r\n",
    "    sep=\",\",\r\n",
    "    quoting=csv.QUOTE_ALL)\r\n",
    "\r\n",
    "# --- DROP --- HasInstagram, and Est. Date of Participation from filtered users\r\n",
    "df_filtered_users.drop(['HasInstagram', 'Est. Date of Participation'], axis = 1, inplace=True)\r\n",
    "\r\n",
    "# --- DROP --- Date_Created and Is_Truncated from tweets \r\n",
    "df_twt_tweets.drop(['Date_Created', 'Is_Truncated'], axis = 1, inplace=True)\r\n",
    "\r\n",
    "# --- DROP --- rows wherein => HasTwitter is FALSE\r\n",
    "df_filtered_users.drop(df_filtered_users[df_filtered_users['HasTwitter'] == False].index, inplace=True)\r\n",
    "\r\n",
    "# --- DROP --- rows wherein => Nationality is NOT Filipino\r\n",
    "#NOTE: JUST a precaution bc i can't be too sure lmao\r\n",
    "df_filtered_users.drop(df_filtered_users[~df_filtered_users['Nationality'].str.contains('Filipino')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some descriptive statistics about both users and tweets I thought would be useful. The stats pre- and post-removal of auto-generated tweets is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [USERS] ---\r\n",
    "# --- PRINT --- COUNT\r\n",
    "print(\"Total number of user: \" + str(df_filtered_users['HasTwitter'].count()))\r\n",
    "print(\"--------------------\")\r\n",
    "\r\n",
    "# --- PRINT --- Nationality\r\n",
    "# comment: \"Mixed-Filipino\" as containing Filipino + another nationality; wrote it to document nalang after counting the MF  manually\r\n",
    "print(\"Nationality: \")\r\n",
    "print(\"Filipino: 2263\")\r\n",
    "print(\"Mixed-Filipino: 20\")\r\n",
    "print(\"--------------------\")\r\n",
    "\r\n",
    "# --- PRINT --- Sex\r\n",
    "print(\"Sex: \")\r\n",
    "print(df_filtered_users['Sex'].value_counts(ascending=True))\r\n",
    "print(\"--------------------\")\r\n",
    "\r\n",
    "# --- PRINT --- Age\r\n",
    "print(\"Age: \")\r\n",
    "print(df_filtered_users['Age'].describe())\r\n",
    "print(\"--------------------\")\r\n",
    "\r\n",
    "# --- PRINT --- Age\r\n",
    "# comment: didn't see the need to make intervals for age (maybe); left it just in case\r\n",
    "# print(\"Age: \")\r\n",
    "# print(df_filtered_users['Age'].value_counts(bins=4))\r\n",
    "# print(\"--------------------\")\r\n",
    "\r\n",
    "# --- PRINT --- 5 TRAITS\r\n",
    "for trait in traits:\r\n",
    "    print(trait)\r\n",
    "    print(\"Mean: \" + str(df_filtered_users[trait].mean()))\r\n",
    "    print(\"SD: \" + str(df_filtered_users[trait].std()))\r\n",
    "    print(\"Min: \" + str(df_filtered_users[trait].min()))\r\n",
    "    print(\"Max: \" + str(df_filtered_users[trait].max()))\r\n",
    "    print(\"--------------------\")\r\n",
    "\r\n",
    "# --- [TWEETS] ---\r\n",
    "# --- PRINT --- COUNT\r\n",
    "# comment: not sure how to categorize it....\r\n",
    "print(\"Total number of user: \")\r\n",
    "print(df_twt_tweets['Language'].value_counts(ascending=True))\r\n",
    "print(\"--------------------\")\r\n",
    "# ===== END DESCRIPTIVE STATS ====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section drops any users in the twitter_tweet file that does not pass the 100-tweet threshold. It exports the final dataframe into a \"concatex.csv\" file. This file (& the DF) serves as the main dataset for the tweets.\r\n",
    "The csv file should contain only the UserID and the Concatext columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made a copy of the tweets DF so original is untouched; drop the TweetID col\r\n",
    "df_temp_tweets = df_twt_tweets[['TweetID', 'UserID', 'Text']].copy()\r\n",
    "df_temp_tweets = df_temp_tweets.drop(\"TweetID\", axis=1)\r\n",
    "\r\n",
    "#fill blanks and fix encoding\r\n",
    "df_temp_tweets['Text'].fillna(\" \", inplace=True)\r\n",
    "df_temp_tweets['Text'] = df_temp_tweets['Text'].apply(lambda x: fix_encode(x))\r\n",
    "\r\n",
    "#get tweet count based on how many instances of a certain UserID is seen\r\n",
    "tweet_count = pd.DataFrame()\r\n",
    "tweet_count['TweetCount'] = df_temp_tweets['UserID'].value_counts()\r\n",
    "\r\n",
    "#remove users with <100 tweets (which is based on how many times a user id is found)\r\n",
    "tweet_count.drop(tweet_count[tweet_count['TweetCount'] < 100].index, inplace=True)\r\n",
    "\r\n",
    "#index name change. make to new column. reset index.\r\n",
    "tweet_count.index.name = 'UserID'\r\n",
    "tweet_count = tweet_count.reset_index()\r\n",
    "\r\n",
    "#the list of users who passed the threshold; sorts, then compare aginst UserIDs in df_temp_tweets; drop if not found \r\n",
    "users = tweet_count['UserID'].copy()\r\n",
    "df_temp_tweets.sort_values(by=['UserID'], inplace=True)\r\n",
    "df_temp_tweets = df_temp_tweets[df_temp_tweets['UserID'].isin(users)]\r\n",
    "\r\n",
    "#the MAIN dataset for tweets\r\n",
    "df_dataset_tweets = pd.DataFrame()\r\n",
    "df_dataset_tweets['UserID'] = tweet_count['UserID'].copy()\r\n",
    "\r\n",
    "#concatenate all the text of the same UserID then copy\r\n",
    "df_temp_tweets['expand'] = df_temp_tweets.apply(lambda x: \" \".join([x['Text']]), axis = 1)\r\n",
    "df_dataset_tweets = df_temp_tweets.groupby('UserID')['expand'].apply(list).to_frame().copy()\r\n",
    "\r\n",
    "#set the index. make list of strings into 1 string. remove the expand column\r\n",
    "df_dataset_tweets.reset_index(inplace = True)\r\n",
    "df_dataset_tweets['Concatext'] = df_dataset_tweets['expand'].str.join(\" \")\r\n",
    "df_dataset_tweets = df_dataset_tweets.drop('expand', axis=1)\r\n",
    "\r\n",
    "# df_temp_tweets.drop(['TweetID'], axis=1)\r\n",
    "# df_temp_tweets['Text'].fillna(\"\", inplace=True)\r\n",
    "\r\n",
    "df_dataset_tweets.to_csv(\r\n",
    "    r'concatex.csv',\r\n",
    "    encoding=\"utf-8\",\r\n",
    "    sep=\",\",\r\n",
    "    quoting=csv.QUOTE_ALL)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any Users in ***df_dataset_tweets*** that are not found in ***filtered_users***. /n\r\n",
    "The next line drops the other way around. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283, 10)\n",
      "(2112, 2)\n"
     ]
    }
   ],
   "source": [
    "filtered_users = df_filtered_users['UserID'].copy()\r\n",
    "df_dataset_tweets = df_dataset_tweets[df_dataset_tweets['UserID'].isin(filtered_users)]\r\n",
    "\r\n",
    "print(df_filtered_users.shape)\r\n",
    "print(df_dataset_tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOR TESTING PURPOSES ONLY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: printing the head and tail of both UserID and Concatext: everything seems okay? PAGDADASAL KO 'TO\r\n",
    "# print(df_dataset_tweets['UserID'].head(15))\r\n",
    "# print(df_dataset_tweets['UserID'].tail(15))\r\n",
    "# print(df_dataset_tweets['Concatext'].head(1))\r\n",
    "# print(df_dataset_tweets['Concatext'].tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes a df of each personality trait, containing only the UserID and the respective trait. Performs an **INNER JOIN** so that only rows found in both df_filtered_users and df_dataset_tweets are copied into the new DataFrames. The key used is *UserID*. **** WALA NA SILBI FOR NOW ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personality_master = pd.merge(df_filtered_users, df_dataset_tweets, on='UserID', how='inner')\r\n",
    "\r\n",
    "df_personality_Openness = df_personality_master[['UserID', 'Openness', 'Concatext']].copy()\r\n",
    "df_personality_Conscientiousness = df_personality_master[['UserID', 'Conscientiousness', 'Concatext']].copy()\r\n",
    "df_personality_Extraversion = df_personality_master[['UserID', 'Extraversion', 'Concatext']].copy()\r\n",
    "df_personality_Agreeableness = df_personality_master[['UserID', 'Agreeableness', 'Concatext']].copy()\r\n",
    "df_personality_Neuroticism = df_personality_master[['UserID', 'Neuroticism', 'Concatext']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building and Evaluation. Algorithms to use are LIN, RIN, and SVR (w/ RBF kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "from numpy import mean\r\n",
    "from numpy import arange\r\n",
    "from numpy import std\r\n",
    "from numpy import absolute\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "# from tweetokenize import Tokenizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import cross_validate\r\n",
    "from sklearn.metrics import make_scorer\r\n",
    "from sklearn.metrics import r2_score\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.linear_model import Ridge\r\n",
    "from sklearn.svm import SVR\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.preprocessing import MaxAbsScaler\r\n",
    "from sklearn.dummy import DummyRegressor\r\n",
    "import pandas as pd \r\n",
    "\r\n",
    "# TOKENIZER = Tokenizer(\r\n",
    "# \tlowercase = False,\r\n",
    "# \tallcapskeep = True,\r\n",
    "# \tnormalize = False,\r\n",
    "# \tusernames = '__USERNAME__',\r\n",
    "# \turls = '__URL__',\r\n",
    "# \thashtags = '__HASHTAG__',\r\n",
    "# \tnumbers = \"__NUMBER__\",\r\n",
    "# \tignorequotes = False,\r\n",
    "# \tignorestopwords = False)\r\n",
    "\r\n",
    "clfs = [\r\n",
    "    DummyRegressor(strategy='mean'),\r\n",
    "    LinearRegression(),\r\n",
    "    Ridge(),\r\n",
    "    SVR()]\r\n",
    "\r\n",
    "results = []\r\n",
    "rr_param_grid = [{'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}]\r\n",
    "svr_param_grid = [{'kernel': ['rbf'],'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}]\r\n",
    "\r\n",
    "cross_val_k_folds = KFold(\r\n",
    "            n_splits=10,\r\n",
    "            random_state=10,\r\n",
    "            shuffle=True)\r\n",
    "\r\n",
    "eval_scoring={'mse': 'neg_mean_squared_error', 'rsq': 'r2'}\r\n",
    "\r\n",
    "#root mean squared error\r\n",
    "def eval_compute_rmse(test, pred):\r\n",
    "    return np.sqrt(mean_squared_error(test, pred))\r\n",
    "\r\n",
    "#r square\r\n",
    "def eval_compute_rsq(test, pred):\r\n",
    "    return r2_score(test, pred)\r\n",
    "\r\n",
    "def cross_validate(trait, clf, x_train, y_train):\r\n",
    "    eval_rmse = np.array([])\r\n",
    "    eval_rsq = np.array([])\r\n",
    "    for train_index, test_index in cross_val_k_folds.split(x_train):\r\n",
    "        cv_x_train, cv_x_test = x_train[train_index], x_train[test_index]\r\n",
    "        cv_y_train, cv_y_test = y_train[train_index], y_train[test_index]\r\n",
    "        \r\n",
    "        model = clf.fit(cv_x_train, cv_y_train)\r\n",
    "        cv_y_pred = clf.predict(cv_x_test)\r\n",
    "\r\n",
    "        eval_rmse = np.append(eval_rmse, [eval_compute_rmse(cv_y_test, cv_y_pred)])\r\n",
    "        eval_rsq = np.append(eval_rsq, [eval_compute_rsq(cv_y_test, cv_y_pred)])\r\n",
    "    \r\n",
    "    results = {\r\n",
    "\t\t'type': \"cross_validation\",\r\n",
    "\t\t'trait': trait,\r\n",
    "\t\t'clf': str(clf)[:str(clf).find('(')],\r\n",
    "\t\t'rmse': eval_rmse.mean(),\r\n",
    "\t\t'rmse_std': eval_rmse.std()\r\n",
    "    }\r\n",
    "    \r\n",
    "    return results\r\n",
    "\r\n",
    "def cross_validate_rr(trait, clf, x_train, y_train, params_grid):\r\n",
    "    scorer = make_scorer(eval_compute_rmse, greater_is_better=False)\r\n",
    "    rid_gs = GridSearchCV(clf, params_grid, cv=cross_val_k_folds, scoring= scorer)\r\n",
    "    rid_gs.fit(x_train, y_train)\r\n",
    "    results = {\r\n",
    "        'type': 'cross_validation',\r\n",
    "        'trait': trait,\r\n",
    "        'clf': str(clf)[:str(clf).find('(')],\r\n",
    "        'rmse': rid_gs.cv_results_['mean_test_score'][rid_gs.best_index_],\r\n",
    "        'rmse_std': rid_gs.cv_results_['std_test_score'][rid_gs.best_index_]\r\n",
    "    }\r\n",
    "    return results, rid_gs.best_params_\r\n",
    "\r\n",
    "def cross_validate_svr(trait, clf, x_train, y_train, params_grid):\r\n",
    "    scorer = make_scorer(eval_compute_rmse, greater_is_better=False)\r\n",
    "    svr_gs = GridSearchCV(clf, params_grid, cv=cross_val_k_folds, scoring= scorer, verbose=2)\r\n",
    "    svr_gs.fit(x_train, y_train)\r\n",
    "    results = {\r\n",
    "        'type': 'cross_validation',\r\n",
    "        'trait': trait,\r\n",
    "        'clf': str(clf)[:str(clf).find('(')],\r\n",
    "        'rmse': svr_gs.cv_results_['mean_test_score'][svr_gs.best_index_],\r\n",
    "        'rmse_std': svr_gs.cv_results_['std_test_score'][svr_gs.best_index_]\r\n",
    "    }\r\n",
    "    return results, svr_gs.best_params_\r\n",
    "\r\n",
    "df_model = pd.DataFrame()\r\n",
    "labels = df_personality_master[['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']]\r\n",
    "\r\n",
    "for trait in traits:\r\n",
    "    #train test split\r\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\r\n",
    "        df_dataset_tweets.Concatext,\r\n",
    "        labels[trait],\r\n",
    "        test_size = 0.4, \r\n",
    "        random_state = 101)\r\n",
    "\r\n",
    "    TFIDF_vectorizer = TfidfVectorizer(\r\n",
    "        min_df = 0.05, \r\n",
    "        max_features = 3000\r\n",
    "    )\r\n",
    "\r\n",
    "    SCALER = MaxAbsScaler()\r\n",
    "\r\n",
    "    x_train = TFIDF_vectorizer.fit_transform(x_train)\r\n",
    "    x_test = TFIDF_vectorizer.fit_transform(x_test)\r\n",
    "\r\n",
    "    x_train = SCALER.fit_transform(x_train)\r\n",
    "    x_test = SCALER.fit_transform(x_test)\r\n",
    "\r\n",
    "    y_train = SCALER.fit_transform(y_train.to_numpy().reshape(-1, 1)) #().reshape(-1, 1)\r\n",
    "    y_test = SCALER.transform(y_test.to_numpy().reshape(-1, 1)) #().reshape(-1, 1)\r\n",
    "\r\n",
    "    for clf in clfs:\r\n",
    "        if str(clf)[:str(clf).find('(')] == \"Ridge\":\r\n",
    "            cv_result, cv_best_params = cross_validate_rr(trait, clf, x_train, y_train, rr_param_grid)\r\n",
    "            clf.set_params(**cv_best_params)\r\n",
    "            print(cv_best_params)\r\n",
    "        elif str(clf)[:str(clf).find('(')] != \"SVR\":\r\n",
    "            cv_result = cross_validate(trait, clf, x_train, y_train)\r\n",
    "        else: \r\n",
    "            cv_result, cv_best_params = cross_validate_svr(trait, clf, x_train, y_train, svr_param_grid)\r\n",
    "            clf.set_params(**cv_best_params)\r\n",
    "            print(cv_best_params)\r\n",
    "            \r\n",
    "        results.append(cv_result)\r\n",
    "\r\n",
    "        print(\"-------------- TESTING --------------\")\r\n",
    "        # actual testing\r\n",
    "        model = clf.fit(x_train, y_train)\r\n",
    "        y_pred = clf.predict(x_test)\r\n",
    "\r\n",
    "        results.append({\r\n",
    "            'type': \"testing\",\r\n",
    "            'trait': trait,\r\n",
    "            'clf': str(clf)[:str(clf).find('(')],\r\n",
    "            'rmse': eval_compute_rmse(y_test, y_pred),\r\n",
    "            'r2': eval_compute_rsq(y_test, y_pred)\r\n",
    "        })\r\n",
    "\r\n",
    "        df_model = pd.DataFrame(results)\r\n",
    "        df_model.set_index(\"trait\", inplace=True)\r\n",
    "        df_model.to_csv(\r\n",
    "            \"model_results_tfidf.csv\",\r\n",
    "            quoting=csv.QUOTE_ALL,\r\n",
    "            sep=',',\r\n",
    "            encoding='utf-8'\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_processed_tweets.shape)\r\n",
    "df_processed_tweets = df_processed_tweets.drop(\"TweetID\", axis = 1)\r\n",
    "\r\n",
    "#fill blanks and fix encoding\r\n",
    "df_processed_tweets['Text'].fillna(\" \", inplace=True)\r\n",
    "df_processed_tweets['Text'] = df_processed_tweets['Text'].apply(lambda x: fix_encode(x))\r\n",
    "\r\n",
    "#get tweet count based on how many instances of a certain UserID is seen\r\n",
    "processed_tweet_count = pd.DataFrame()\r\n",
    "processed_tweet_count['TweetCount'] = df_processed_tweets['UserID'].value_counts()\r\n",
    "\r\n",
    "#remove users with <100 tweets (which is based on how many times a user id is found)\r\n",
    "processed_tweet_count.drop(processed_tweet_count[processed_tweet_count['TweetCount'] < 100].index, inplace=True)\r\n",
    "\r\n",
    "#index name change. make to new column. reset index.\r\n",
    "processed_tweet_count.index.name = 'UserID'\r\n",
    "processed_tweet_count = processed_tweet_count.reset_index()\r\n",
    "\r\n",
    "#the list of users who passed the threshold; sorts, then compare aginst UserIDs in df_temp_tweets; drop if not found \r\n",
    "processedtwt_users = tweet_count['UserID'].copy()\r\n",
    "df_processed_tweets.sort_values(by=['UserID'], inplace=True)\r\n",
    "df_processed_tweets = df_processed_tweets[df_processed_tweets['UserID'].isin(processedtwt_users)]\r\n",
    "\r\n",
    "#the MAIN dataset for PROCtweets\r\n",
    "df_dataset_processed_tweets = pd.DataFrame()\r\n",
    "df_dataset_processed_tweets['UserID'] = processed_tweet_count['UserID'].copy()\r\n",
    "\r\n",
    "#concatenate all the text of the same UserID then copy\r\n",
    "df_processed_tweets['expand'] = df_processed_tweets.apply(lambda x: \" \".join([x['Text']]), axis = 1)\r\n",
    "df_dataset_processed_tweets = df_processed_tweets.groupby('UserID')['expand'].apply(list).to_frame().copy()\r\n",
    "\r\n",
    "#set the index. make list of strings into 1 string. remove the expand column\r\n",
    "df_dataset_processed_tweets.reset_index(inplace = True)\r\n",
    "df_dataset_processed_tweets['Concatext'] = df_dataset_processed_tweets['expand'].str.join(\" \")\r\n",
    "df_dataset_processed_tweets = df_dataset_processed_tweets.drop('expand', axis=1)\r\n",
    "\r\n",
    "# df_temp_tweets.drop(['TweetID'], axis=1)\r\n",
    "# df_temp_tweets['Text'].fillna(\"\", inplace=True)\r\n",
    "\r\n",
    "df_dataset_processed_tweets.to_csv(\r\n",
    "    r'concatex_processed.csv',\r\n",
    "    encoding=\"utf-8\",\r\n",
    "    sep=\",\",\r\n",
    "    quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.clear()\r\n",
    "\r\n",
    "df_model_processedtwt = pd.DataFrame()\r\n",
    "\r\n",
    "for trait in traits:\r\n",
    "    #train test split\r\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\r\n",
    "        df_dataset_processed_tweets.Concatext,\r\n",
    "        labels[trait],\r\n",
    "        test_size = 0.4, \r\n",
    "        random_state = 101)\r\n",
    "\r\n",
    "    TFIDF_vectorizer = TfidfVectorizer(\r\n",
    "        min_df = 0.05, \r\n",
    "        max_features = 3000\r\n",
    "    )\r\n",
    "\r\n",
    "    SCALER = MaxAbsScaler()\r\n",
    "\r\n",
    "    x_train = TFIDF_vectorizer.fit_transform(x_train)\r\n",
    "    x_test = TFIDF_vectorizer.fit_transform(x_test)\r\n",
    "\r\n",
    "    x_train = SCALER.fit_transform(x_train)\r\n",
    "    x_test = SCALER.fit_transform(x_test)\r\n",
    "\r\n",
    "    y_train = SCALER.fit_transform(y_train.to_numpy().reshape(-1, 1)) #().reshape(-1, 1)\r\n",
    "    y_test = SCALER.transform(y_test.to_numpy().reshape(-1, 1)) #().reshape(-1, 1)\r\n",
    "\r\n",
    "    for clf in clfs:\r\n",
    "        if str(clf)[:str(clf).find('(')] == \"Ridge\":\r\n",
    "            cv_result, cv_best_params = cross_validate_rr(trait, clf, x_train, y_train, rr_param_grid)\r\n",
    "            clf.set_params(**cv_best_params)\r\n",
    "            print(cv_best_params)\r\n",
    "        elif str(clf)[:str(clf).find('(')] != \"SVR\":\r\n",
    "            cv_result = cross_validate(trait, clf, x_train, y_train)\r\n",
    "        else: \r\n",
    "            cv_result, cv_best_params = cross_validate_svr(trait, clf, x_train, y_train, svr_param_grid)\r\n",
    "            clf.set_params(**cv_best_params)\r\n",
    "            print(cv_best_params)\r\n",
    "            \r\n",
    "        results.append(cv_result)\r\n",
    "\r\n",
    "        print(\"-------------- TESTING --------------\")\r\n",
    "        # actual testing\r\n",
    "        model_processedtwt = clf.fit(x_train, y_train)\r\n",
    "        y_pred = clf.predict(x_test)\r\n",
    "\r\n",
    "        results.append({\r\n",
    "            'type': \"testing\",\r\n",
    "            'trait': trait,\r\n",
    "            'clf': str(clf)[:str(clf).find('(')],\r\n",
    "            'rmse': eval_compute_rmse(y_test, y_pred),\r\n",
    "            'r2': eval_compute_rsq(y_test, y_pred)\r\n",
    "        })\r\n",
    "\r\n",
    "        df_model_processedtwt = pd.DataFrame(results)\r\n",
    "        df_model_processedtwt.set_index(\"trait\", inplace=True)\r\n",
    "        df_model_processedtwt.to_csv(\r\n",
    "            \"model_results_tfidf_processed_nopiv.csv\",\r\n",
    "            quoting=csv.QUOTE_ALL,\r\n",
    "            sep=',',\r\n",
    "            encoding='utf-8'\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results = pd.read_csv(\r\n",
    "    \"model_results_tfidf.csv\",\r\n",
    "    quoting=csv.QUOTE_ALL,\r\n",
    "    sep=\",\",\r\n",
    "    encoding=\"utf-8\"\r\n",
    ")\r\n",
    "\r\n",
    "print(print_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0f5bd28ee32a81f75b587c4a5c9ba5abfdf032b3105de37173de2ab9e920c5085"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}