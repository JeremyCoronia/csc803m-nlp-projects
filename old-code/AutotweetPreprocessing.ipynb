{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "IMPORT FILES\n",
        "\n",
        "NOTE: \n",
        "- In most cases, it is best to avoid regex to reduce time execution\n",
        "- The main process to remove the auto generated tweets:\n",
        "    - Get all the indexes of the autogenerated tweets (df[df['Text].str.contains(CONDITION)].index)\n",
        "    - use the function df.drop(INDEX)\n",
        "- The common regex format on this code is (r\"(?=.*WORDS TO ADD)\")\n",
        "    - \".\" means that it can be represented by any character\n",
        "    - \"*\" means that the character before it can occur 0 to infinite times\n",
        "    - \\d means that it should contain any digit character\n",
        "    - \"[A-Z]\" means that any character that has uppercase letters\n",
        "- Took note of all the initial counts of each part to later on compare how many lines were removed after dropping lines\n",
        "- Used autotime library (pip install ipython-autotime)\n",
        "    - Just add the code \"%%time\" on each note to output the execution time\n",
        "    - make sure autotime is installed\n",
        "\n",
        "- TERMS\n",
        "    - CPU Time: Time that processor is working\n",
        "    - Wall Time: Time that it takes for the whole process to finish\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "StxIihUnA7wR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df1 count: 4018626\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\r\n",
        "import csv\r\n",
        "import re\r\n",
        "\r\n",
        "pd.set_option('display.max_rows', None)\r\n",
        "pd.set_option('display.max_colwidth', None) #changed -1 to \"None\". -passing of negative integer is deprecated\r\n",
        "df1 = pd.read_csv(\r\n",
        "    \"twitter_tweet.csv\",\r\n",
        "    encoding=\"utf-8\",\r\n",
        "    sep=\",\",\r\n",
        "    quoting=csv.QUOTE_ALL)\r\n",
        "url_regex = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\"\r\n",
        "\r\n",
        "df1.drop(['Date_Created', 'Is_Truncated', 'Language'], axis=1, inplace=True)\r\n",
        "\r\n",
        "init_count1 = df1.count().Text\r\n",
        "print(\"df1 count: {}\".format(init_count1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ftfy import fix_encoding\r\n",
        "\r\n",
        "def fix_encode(x):\r\n",
        "    return fix_encoding(x)\r\n",
        "\r\n",
        "df1['Text'].fillna(\"\", inplace=True)\r\n",
        "\r\n",
        "df1.Text = df1.Text.apply(fix_encode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 1: TWITTER STATS\n",
        "\n",
        "- Each segment of the code here does the same thing and each of them works on each of the 4 parts\n",
        "- All the other notes have the same format\n",
        "- some codes store data frame objects on a variable and some not \n",
        "    - Example:\n",
        "        - Stored in variable: partOne2 = df1[df1['Text'].str.contains(\"Our biggest fans this week:\", na=False)].index \n",
        "        - Not stored in variable: df1.drop(df1[df1['Text'].str.contains(\"Our biggest fans this week:\", na=False)].index, inplace=True)\n",
        "    - They have the same purpose but have slightly different times to execute (but average times are very similar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df1 count as of theme 1: 3990403\n",
            "how many tweets were affected in theme 1: 28223\n"
          ]
        }
      ],
      "source": [
        "# 1. count how many tweets affected / themes (to tabular)\r\n",
        "# 2. how many users affected by this (counting TweetIDs < -- > UserIDs)\r\n",
        "\r\n",
        "# %%time\r\n",
        "#All auto generated tweets that contain the word 'follow' with a link will be removed\r\n",
        "partOne1 = df1[df1['Text'].str.contains(r'^(?=.*follow)(?=.* (-via|Via:|Courtesy:|app:|using|with|by|via|to|of|with|daily|it|courtesy|here|thank you|here|old|Justunfollow|yours|out|agree|back) ' + url_regex + ')', na=False, flags=re.IGNORECASE, regex=True)].index\r\n",
        "df1.drop(partOne1, inplace=True) \r\n",
        "#All tweets that contain the words \"Our biggest fans this week:\" will be removed\r\n",
        "partOne2 = df1[df1['Text'].str.contains(\"Our biggest fans this week:\", na=False)].index\r\n",
        "df1.drop(partOne2, inplace=True)\r\n",
        "#All tweets that contain the words \"week\" and \"twitter\" will be removed\r\n",
        "#This is one of the cases where Regex is more preferred since using the contains() only will separate it into 4 lines which will take longer time to execute\r\n",
        "partOne3 = df1[df1['Text'].str.contains(r'^(?=(My week on Twitter ��:|This week on twitter:|How I did on Twitter this week:|My week on Twitter:))', na=False, flags=re.IGNORECASE, regex=True)].index\r\n",
        "df1.drop(partOne3, inplace=True)\r\n",
        "\r\n",
        "print(\"df1 count as of theme 1: {}\".format(df1.count().Text))\r\n",
        "print(\"how many tweets were affected in theme 1: {}\".format(str(init_count1 - df1.count().Text)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 2: HOROSCOPE\n",
        "\n",
        "99% of the horoscope tweets are in the format \"statement ... More for \"horoscope\" \"link\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2] how many tweets before preprocessing: 3990403\n",
            "[2] how many tweets there are as of preprocessing: 3978972\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "\r\n",
        "print(\"[2] how many tweets before preprocessing: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"... More for\", na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"Horoscopes - Zodiac Astrology \", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "print(\"[2] how many tweets there are as of preprocessing: {}\".format(df1.count().Text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 3: MEDIA (MUSIC/VIDEO) RELATED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3] how many tweets before preprocessing: 3978972\n",
            "[3] how many tweets there are as of preprocessing: 3975635\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "print(\"[3] how many tweets before preprocessing: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "themeThreePartOne1 = df1[df1['Text'].str.contains(\"I liked a @YouTube video\", na=False)].index\r\n",
        "df1.drop(themeThreePartOne1, inplace=True)\r\n",
        "\r\n",
        "themeThreePartThree2 = df1[df1['Text'].str.contains(r\"^(?=.* vote)(?=.*YouTube Music Awards)\", na=False, flags=re.IGNORECASE, regex=True)].index\r\n",
        "df1.drop(themeThreePartThree2, inplace=True)\r\n",
        "\r\n",
        "themeThreePartOne3 = df1[df1['Text'].str.contains(\"What song can't you stop listening to?\", na=False)].index\r\n",
        "df1.drop(themeThreePartOne3, inplace=True)\r\n",
        "\r\n",
        "themeThreePartThree4 = df1[df1['Text'].str.contains(\"New favourite:\", na=False)].index\r\n",
        "df1.drop(themeThreePartThree4, inplace=True)\r\n",
        "\r\n",
        "themeThreePartOne5 = df1[df1['Text'].str.contains(\"#NowPlaying\", na=False)].index\r\n",
        "df1.drop(themeThreePartOne5, inplace=True)\r\n",
        "\r\n",
        "themeThreePartThree6 = df1[df1['Text'].str.contains(\"#TorchMusic\", na=False)].index\r\n",
        "df1.drop(themeThreePartThree6, inplace=True)\r\n",
        "\r\n",
        "themeThreePartFour7 = df1[df1['Text'].str.contains(r\"^(?=.*I listened to )(?=.*of music \" + url_regex + \")\", na=False, regex=True)].index\r\n",
        "df1.drop(themeThreePartFour7, inplace=True)\r\n",
        "\r\n",
        "themeThreePartFour8 = df1[df1['Text'].str.contains(\"@gokpop\", na=False)].index\r\n",
        "df1.drop(themeThreePartFour8, inplace=True)\r\n",
        "\r\n",
        "themeThreePartOne9 = df1[df1['Text'].str.contains(\"#Smule\", na=False)].index\r\n",
        "df1.drop(themeThreePartOne9, inplace=True)\r\n",
        "\r\n",
        "print(\"[3] how many tweets there are as of preprocessing: {}\".format(df1.count().Text))\r\n",
        "# 17.9s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 4: MISCELLANEOUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4] how many tweets before preprocessing: 3975635\n",
            "[4] how many tweets there are as of preprocessing: 3975272\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "print(\"[4] how many tweets before preprocessing: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"How old will you be on your next birthday?\", na=False)].index,  inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#PS4live\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"I just connected with friends on #BBM. Follow the link to add my PIN:\", na=False, regex=True)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=\\d of 5 stars)\", na=False, regex=True)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#YearwithUber\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=.*#MyTwitterAnniversary)(?=.*(Do you remember when you joined Twitter?|I have been on Twitter for))\", na=False, regex=True)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#carousell @thecarousell\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "# df1.drop(df1[df1['Text'].str.contains(\"This week I sent ��\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"This week I sent \", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"@dreamgiverph\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "print(\"[4] how many tweets there are as of preprocessing: {}\".format(df1.count().Text))\r\n",
        "#22.5s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 5: GAMES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5] how many tweets before preprocessing: 3975272\n",
            "[5] how many tweets there are as of preprocessing: 3974747\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "print(\"[5] how many tweets before preprocessing: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=.*(CLUMSY NINJA|#ClumsyNinja))\", na=False, regex=True)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"in DragonVale\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"Play Archie:\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#BoardKings\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#toydefense2\", na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"I'm playing Shopee Mission on Shopee!\", na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#ArtemisStalkerSkin\", na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#CSRRacing\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#RulesofSurvival\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"Pororo Penguin Run\", na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"The ultimate Harry Potter quiz:\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "print(\"[5] how many tweets there are as of preprocessing: {}\".format(df1.count().Text))\r\n",
        "#21.3s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 6: GIVEAWAYS, WIN SOMETHING, PRIZES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6] how many tweets before preprocessing: 3974747\n",
            "[6] how many tweets there are as of preprocessing: 3973720\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "print(\"[6] how many tweets before preprocessing: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=.* (giveaway|give away|giving away|set up for grabs))(?=.*\"+url_regex+\")\", na=False, flags=re.IGNORECASE, regex=True)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"#bdodealfinder\", na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=.*#0917wonderful)(?=.*@enjoyGlobe)\", na=False, regex=True)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=.*Globe)(?=.*gifts)\", na=False, regex=True)].index, inplace=True)\r\n",
        "\r\n",
        "print(\"[6] how many tweets there are as of preprocessing: {}\".format(df1.count().Text))\r\n",
        "#15.4s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 7: LOCATION & SERVICES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7] how many tweets before preprocessing: 3973720\n",
            "[7] how many tweets there are as of preprocessing: 3971939\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "print(\"[7] how many tweets before preprocessing: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains('using @waze', na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains('on @waze', na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=I'm at ([A-Z]|\\d))\", na=False, regex=True)].index, inplace=True)\r\n",
        "\r\n",
        "print(\"[7] how many tweets there are as of preprocessing: {}\".format(df1.count().Text))\r\n",
        "#9.1s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 8: SOCIAL MEDIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8] how many tweets before preprocessing: 3971939\n",
            "[8] how many tweets there are as of preprocessing: 3970215\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "print(\"[8] how many tweets before preprocessing: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=.* via)(?=.* We Heart It)\", na=False, flags=re.IGNORECASE, regex=True)].index, inplace=True)\r\n",
        "\r\n",
        "#FB\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"I posted a new photo to Facebook\", na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"I posted a new video to Facebook\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "#Instagram\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"Just posted a photo\", na=False)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"Just posted a video\", na=False)].index, inplace=True)\r\n",
        "\r\n",
        "print(\"[8] how many tweets there are as of preprocessing: {}\".format(df1.count().Text))\r\n",
        "#11.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THEME 9: VIA ANOTHER PLATFORM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9] how many tweets before preprocessing: 3970215\n",
            "[9] how many tweets there are as of preprocessing: 3969745\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "print(\"[9] how many tweets before preprocessing: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=.*Sign the Petition!)(?=.*via @Change)\", na=False, regex=True)].index, inplace=True)\r\n",
        "df1.drop(df1[df1['Text'].str.contains(\"@ChangeOrg_ID\")].index, inplace=True)\r\n",
        "\r\n",
        "df1.drop(df1[df1['Text'].str.contains(r\"^(?=Ask me a question)(?=.* \" + url_regex + \")\", na=False, regex=True)].index, inplace=True)\r\n",
        "\r\n",
        "print(\"[9] how many tweets there are as of preprocessing: {}\".format(df1.count().Text))\r\n",
        "#17.8s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Export Filtered CSV File\n",
        "\n",
        "- Concatenates all the dataframes into one csv file using the function pd.concat([dataframe1, dataframe2, ..., dataframen])\n",
        "- Saves it into a csv file using the function data_frame_object.to_csv(location)\n",
        "- index=True is an argument in the to_csv function to maintain the indexes (in this case, user tweet ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INITIAL count of tweets: 4018626\n",
            "FINAL count of tweets: 3969745\n"
          ]
        }
      ],
      "source": [
        "# %%time\r\n",
        "# new_df = pd.concat([df1,df2,df3,df4])\r\n",
        "print(\"INITIAL count of tweets: {}\".format(init_count1))\r\n",
        "print(\"FINAL count of tweets: {}\".format(df1.count().Text))\r\n",
        "\r\n",
        "df1.to_csv(r'processed_tweets_dataset_nonconcat.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(str(init_count1 - df1.count().Text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "WALK THROUGH: Mounting Files + Quick Searching.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "f5bd28ee32a81f75b587c4a5c9ba5abfdf032b3105de37173de2ab9e920c5085"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}