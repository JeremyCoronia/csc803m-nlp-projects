{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this BINARY CLASSIFIER to be used is [bc-dataset.csv].\r\n",
    "There are 2 implementations here:\r\n",
    "1. **Bag of words approach.**\r\n",
    "2. Word vectors (can be pre-trained word embeddings).\r\n",
    "\r\n",
    "The dataset split is 60-40.\r\n",
    "Evaluation metrics to be used in this are:\r\n",
    "1. Precision.\r\n",
    "2. Recall.\r\n",
    "3. F-Measure.\r\n",
    "\r\n",
    "\r\n",
    "References:\r\n",
    "1. https://www.kaggle.com/homayoonkhadivi/twitter-gender-classification-high-acc-69-56-nlp#I-gained-the-top-high-accuracy-with-LogisticRegression-algorithm-for-this-problem \r\n",
    "2. https://www.kaggle.com/evilport/classify-gender-with-description-and-text\r\n",
    "3. https://www.kaggle.com/orhansertkaya/natural-language-processing-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (20050, 3)\n"
     ]
    }
   ],
   "source": [
    "from ftfy import fix_encoding\r\n",
    "import pandas as pd\r\n",
    "import random\r\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\r\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
    "from sklearn.utils import shuffle\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import csv\r\n",
    "import nltk as nlp\r\n",
    "from nltk.corpus import stopwords\r\n",
    "\r\n",
    "nlp.download(\"stopwords\")\r\n",
    "nlp.download('punkt')\r\n",
    "nlp.download('wordnet')\r\n",
    "\r\n",
    "def fix_encode(x):\r\n",
    "    return fix_encoding(x)\r\n",
    "\r\n",
    "pd.set_option('display.max_rows', None)\r\n",
    "pd.set_option('display.max_colwidth', None)\r\n",
    "\r\n",
    "df = pd.read_csv(\r\n",
    "    \"datasets/bc-dataset.csv\",\r\n",
    "    encoding=\"latin1\",\r\n",
    "    sep=\",\",\r\n",
    "    quoting=csv.QUOTE_ALL\r\n",
    ")\r\n",
    "\r\n",
    "data = pd.concat([df.gender, df['gender:confidence'], df.text], axis=1)\r\n",
    "\r\n",
    "#drop null rows\r\n",
    "print(\"Data Shape: \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows some descriptive stats (just for fun).\r\n",
    "Also applies ftfy encoding to the ['text'] Column to fix any broken encodings when the .csv file was loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (20050, 3)\n",
      "Data Columns: Index(['gender', 'gender:confidence', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape: \" + str(data.shape))\r\n",
    "print(\"Data Columns: \" + str(data.columns))\r\n",
    "\r\n",
    "# print(\"Just some stats.\")\r\n",
    "# print(\"------\")\r\n",
    "# print(data['gender'].describe())\r\n",
    "# print(\"------\")\r\n",
    "# print(data['gender'].value_counts(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNKNOWN and NAN values in *gender* column are discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total female tweets:  6700\n",
      "total male tweets:    6194\n",
      "total brand tweets:   5942\n"
     ]
    }
   ],
   "source": [
    "data.gender = [0 if gender == 'female' else 1 for gender in data.gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a5da540e092f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# for testing purposes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# data.iloc[231]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# for testing purposes\r\n",
    "# data.iloc[231]\r\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18836, 3)\n",
      "(18836, 3)\n"
     ]
    }
   ],
   "source": [
    "print(str(data.shape))\r\n",
    "data.dropna(subset=['text', 'gender'], inplace=True)\r\n",
    "data = data.reset_index(drop=True)\r\n",
    "\r\n",
    "data.text = data.text.apply(lambda x: fix_encode(x))\r\n",
    "\r\n",
    "# Data Shape: (20050, 26)\r\n",
    "# Data Shape: (16306, 26)\r\n",
    "print(str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \r\n",
    "\r\n",
    "def remove_URL(text):\r\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\r\n",
    "    return url.sub(r'',text)\r\n",
    "\r\n",
    "def remove_html(text):\r\n",
    "    html=re.compile(r'<.*?>')\r\n",
    "    return html.sub(r'',text)\r\n",
    "\r\n",
    "def remove_emoji(text):\r\n",
    "    emoji_pattern = re.compile(\"[\"\r\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\r\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\r\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\r\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\r\n",
    "                           u\"\\U00002702-\\U000027B0\"\r\n",
    "                           u\"\\U000024C2-\\U0001F251\"\r\n",
    "                           \"]+\", flags=re.UNICODE)\r\n",
    "    return emoji_pattern.sub(r'', text)\r\n",
    "\r\n",
    "def remove_punct(text):\r\n",
    "    table=str.maketrans('','',string.punctuation)\r\n",
    "    return text.translate(table)\r\n",
    "\r\n",
    "data['text']=data['text'].apply(lambda x : remove_URL(x))\r\n",
    "data['text']=data['text'].apply(lambda x : remove_html(x))\r\n",
    "data['text']=data['text'].apply(lambda x : remove_emoji(x))\r\n",
    "data['text']=data['text'].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:  High marks in the grade cards for these 2 cuties  Great job \n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL: \", data.text.iloc[1237])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13817, 2)\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[data['gender:confidence'] < 0.80].index, inplace=True)\r\n",
    "data.drop('gender:confidence', axis=1, inplace=True)\r\n",
    "# data.dropna(subset=['gender'], inplace=True)\r\n",
    "print(str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:  Girl of the month  \n",
      "PREPROCESSED:  girl month\n"
     ]
    }
   ],
   "source": [
    "lemma = nlp.WordNetLemmatizer()\r\n",
    "description_list = []   # empty list\r\n",
    "tweet_list = []   # empty list\r\n",
    "\r\n",
    "# should pronouns be counted as stopwords?\r\n",
    "\r\n",
    "for each in data.text:\r\n",
    "    each = re.sub(\"[^a-zA-Z]\",\" \", str(each))                                        # regex to clean unnecesarry chars\r\n",
    "    each = each.lower()                                                              # lowercase all\r\n",
    "    each = nlp.word_tokenize(each)                                                   # split all by tokenizing\r\n",
    "    each = [word for word in each if not word in set(stopwords.words(\"english\"))]    # delete stop words from your array\r\n",
    "    each = [lemma.lemmatize(word) for word in each]                                  # lemmatize \"memories\" -> \"memory\"\r\n",
    "    each = \" \".join(each)                                                            # make them one string again\r\n",
    "    tweet_list.append(each)                                                         # put them into big array\r\n",
    "\r\n",
    "print(\"ORIGINAL: \", data.text.iloc[123])\r\n",
    "print(\"PREPROCESSED: \", tweet_list[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13817, 2)\n"
     ]
    }
   ],
   "source": [
    "print(str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "# arbitrarily set it \r\n",
    "MAX_FEATURES = 5000\r\n",
    "\r\n",
    "count_vectorizer = CountVectorizer(max_features=MAX_FEATURES, stop_words='english')\r\n",
    "sparse_matrix = count_vectorizer.fit_transform(tweet_list).toarray()\r\n",
    "words = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab', 'abba', 'abbott', 'abc', 'ability', 'able', 'abortion', 'abraham', 'absolute', 'absolutely', 'abt', 'abu', 'abuse', 'ac', 'academic', 'academy', 'acc', 'accent', 'accept', 'acceptable', 'accepted', 'accepting', 'access', 'accessing', 'accessory', 'accident', 'accidentally', 'accomplishment', 'according', 'account']\n"
     ]
    }
   ],
   "source": [
    "print(words[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=MAX_FEATURES, stop_words='english')\r\n",
    "sparse_matrix_tfidf = tfidf_vectorizer.fit_transform(tweet_list).toarray()\r\n",
    "words_tfidf = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab', 'abba', 'abbott', 'abc', 'ability', 'able', 'abortion', 'abraham', 'absolute', 'absolutely', 'abt', 'abu', 'abuse', 'ac', 'academic', 'academy', 'acc', 'accent', 'accept', 'acceptable', 'accepted', 'accepting', 'access', 'accessing', 'accessory', 'accident', 'accidentally', 'accomplishment', 'according', 'account']\n"
     ]
    }
   ],
   "source": [
    "print(words_tfidf[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "# print(words[:100])\r\n",
    "\r\n",
    "X = sparse_matrix\r\n",
    "y = data.gender.values\r\n",
    "\r\n",
    "X_tfidf = sparse_matrix_tfidf\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\r\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.ensemble import VotingClassifier\r\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.54689   0.65720   0.59699      2112\n",
      "           1    0.46953   0.42372   0.44545      1855\n",
      "           2    0.65779   0.55449   0.60174      1560\n",
      "\n",
      "    accuracy                        0.54985      5527\n",
      "   macro avg    0.55807   0.54513   0.54806      5527\n",
      "weighted avg    0.55223   0.54985   0.54747      5527\n",
      "\n",
      "Mean accuracy:  0.549846209516917\n",
      "WEIGHTED F-measure:  0.5474701894393375\n",
      "WEIGHTED Precision:  0.5522293040760015\n",
      "WEIGHTED Recall:  0.549846209516917\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\r\n",
    "nb_classifier.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_nb = nb_classifier.predict(X_test)\r\n",
    "\r\n",
    "print(classification_report(y_test, y_pred_nb, digits=5))\r\n",
    "print(\"Mean accuracy: \", nb_classifier.score(X_test, y_test))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test, y_pred_nb, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test, y_pred_nb, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test, y_pred_nb, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.51598   0.74482   0.60963      2124\n",
      "           1    0.48127   0.36339   0.41411      1874\n",
      "           2    0.70650   0.48332   0.57398      1529\n",
      "\n",
      "    accuracy                        0.54315      5527\n",
      "   macro avg    0.56792   0.53051   0.53257      5527\n",
      "weighted avg    0.55692   0.54315   0.53348      5527\n",
      "\n",
      "Mean accuracy:  0.543151800253302\n",
      "WEIGHTED F-measure:  0.5334750207805831\n",
      "WEIGHTED Precision:  0.5569185913089071\n",
      "WEIGHTED Recall:  0.543151800253302\n"
     ]
    }
   ],
   "source": [
    "nb_classifier_tfidf = MultinomialNB()\r\n",
    "nb_classifier_tfidf.fit(X_train_tfidf, y_train_tfidf)\r\n",
    "\r\n",
    "y_pred_nb_tfidf = nb_classifier_tfidf.predict(X_test_tfidf)\r\n",
    "\r\n",
    "print(classification_report(y_test_tfidf, y_pred_nb_tfidf, digits=5))\r\n",
    "print(\"Mean accuracy: \", nb_classifier_tfidf.score(X_test_tfidf, y_test_tfidf))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test_tfidf, y_pred_nb_tfidf, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test_tfidf, y_pred_nb_tfidf, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test_tfidf, y_pred_nb_tfidf, average=\"weighted\"))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "SVM = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto')\r\n",
    "SVM.fit(X_train,y_train)\r\n",
    "\r\n",
    "predictions_SVM = SVM.predict(X_test)\r\n",
    "\r\n",
    "# Use accuracy_score function to get the accuracy\r\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.53722   0.64486   0.58614      2171\n",
      "           1    0.46228   0.40594   0.43228      1887\n",
      "           2    0.62342   0.53642   0.57666      1469\n",
      "\n",
      "    accuracy                        0.53447      5527\n",
      "   macro avg    0.54097   0.52907   0.53169      5527\n",
      "weighted avg    0.53455   0.53447   0.53109      5527\n",
      "\n",
      "Mean accuracy:  0.45286774018454856\n",
      "WEIGHTED F-measure:  0.5310898368047072\n",
      "WEIGHTED Precision:  0.4778008853899147\n",
      "WEIGHTED Recall:  0.45286774018454856\n"
     ]
    }
   ],
   "source": [
    "gnb_classifier = GaussianNB()\r\n",
    "gnb_classifier.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_gnb = gnb_classifier.predict(X_test)\r\n",
    "\r\n",
    "print(classification_report(y_test, y_pred_nb, digits=5))\r\n",
    "print(\"Mean accuracy: \", gnb_classifier.score(X_test, y_test))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test, y_pred_nb, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test, y_pred_gnb, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test, y_pred_gnb, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.52846   0.59880   0.56143      2171\n",
      "           1    0.44501   0.41600   0.43002      1887\n",
      "           2    0.59094   0.52417   0.55556      1469\n",
      "\n",
      "    accuracy                        0.51656      5527\n",
      "   macro avg    0.52147   0.51299   0.51567      5527\n",
      "weighted avg    0.51657   0.51656   0.51500      5527\n",
      "\n",
      "Mean accuracy:  0.5165550931789398\n",
      "WEIGHTED F-measure:  0.5150045420458254\n",
      "WEIGHTED Precision:  0.5165749081319531\n",
      "WEIGHTED Recall:  0.5165550931789398\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(max_iter=5000)\r\n",
    "lr_classifier.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred_lr = lr_classifier.predict(X_test)\r\n",
    "\r\n",
    "print(classification_report(y_test, y_pred_lr, digits=5))\r\n",
    "print(\"Mean accuracy: \", lr_classifier.score(X_test, y_test))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test, y_pred_lr, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test, y_pred_lr, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test, y_pred_lr, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.51171   0.59374   0.54968      2171\n",
      "           1    0.42167   0.39799   0.40949      1887\n",
      "           2    0.61043   0.50987   0.55564      1469\n",
      "\n",
      "    accuracy                        0.50461      5527\n",
      "   macro avg    0.51461   0.50053   0.50494      5527\n",
      "weighted avg    0.50721   0.50461   0.50340      5527\n",
      "\n",
      "Mean accuracy:  0.5046137144924914\n",
      "WEIGHTED F-measure:  0.5033997976294795\n",
      "WEIGHTED Precision:  0.5072094202377095\n",
      "WEIGHTED Recall:  0.5046137144924914\n"
     ]
    }
   ],
   "source": [
    "rfc_classifier = RandomForestClassifier(n_estimators = 100)\r\n",
    "rfc_classifier.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_head_rfc = rfc_classifier.predict(X_test)\r\n",
    "\r\n",
    "print(classification_report(y_test, y_head_rfc, digits=5))\r\n",
    "print(\"Mean accuracy: \", rfc_classifier.score(X_test, y_test))\r\n",
    "print(\"WEIGHTED F-measure: \", f1_score(y_test, y_head_rfc, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Precision: \", precision_score(y_test, y_head_rfc, average=\"weighted\"))\r\n",
    "print(\"WEIGHTED Recall: \", recall_score(y_test, y_head_rfc, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0f5bd28ee32a81f75b587c4a5c9ba5abfdf032b3105de37173de2ab9e920c5085"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}